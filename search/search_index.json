{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Computa\u00e7\u00e3o em Nuvem","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#kit-m","title":"KIT-M","text":"<p>Samuel Jabes</p> <p>Lucas Filizola</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2 - Data 11/02/2025</li> <li> Roteiro 3 - Data 20/05/2025</li> <li> Roteiro 4 - Data 22/05/2025</li> <li> Projeto</li> </ul>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"projeto/main/","title":"Simple Authentication API","text":"<p>Este projeto implementa uma API RESTful em Python (FastAPI) capaz de cadastrar e autenticar usu\u00e1rios, al\u00e9m de disponibilizar um endpoint de consulta a dados de terceiros via web scraping.</p>"},{"location":"projeto/main/#sumario","title":"Sum\u00e1rio","text":"<ol> <li>Vis\u00e3o Geral</li> <li>Endpoints</li> <li>Registro de Usu\u00e1rio</li> <li>Autentica\u00e7\u00e3o de Usu\u00e1rio</li> <li>Consulta de Dados</li> <li>Como Executar (Etapa\u00a01)</li> <li>Estrutura de Diret\u00f3rios</li> <li>Docker Hub</li> <li>compose.yaml Final</li> <li>Rodando Localmente</li> <li>Vari\u00e1veis de Ambiente</li> <li>Link Docker Hub</li> <li>Screenshots</li> <li>V\u00eddeo de Demonstra\u00e7\u00e3o</li> </ol>"},{"location":"projeto/main/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>A Simple Authentication API fornece:</p> <ul> <li>Registro de usu\u00e1rios com armazenamento seguro de senhas (usando <code>bcrypt</code>).</li> <li>Login de usu\u00e1rios, retornando um JWT para autentica\u00e7\u00e3o.</li> <li>Consulta protegida (<code>GET /consultar</code>), que executa scraping em uma fonte externa para trazer dados atualizados (por exemplo, cota\u00e7\u00f5es de moedas).</li> </ul> <p>A aplica\u00e7\u00e3o segue boas pr\u00e1ticas de seguran\u00e7a:</p> <ul> <li>Nunca armazena senhas em texto claro.</li> <li>JWT para proteger endpoints.</li> <li>Conex\u00e3o ao PostgreSQL via vari\u00e1veis de ambiente.</li> </ul>"},{"location":"projeto/main/#endpoints","title":"Endpoints","text":""},{"location":"projeto/main/#registro-de-usuario","title":"Registro de Usu\u00e1rio","text":"<pre><code>POST /registrar\nContent-Type: application/json\n</code></pre> <p>Request</p> <pre><code>{\n  \"nome\": \"Samuel Jabes\",\n  \"email\": \"samueljcc@al.insper.edu.br\",\n  \"senha\": \"sam1234\"\n}\n</code></pre> <p>Response (201)</p> <pre><code>{\n  \"jwt\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6InNhbXVlbGpjY0BhbC5pbnNwZXIuZWR1LmJyIiwicGFzc3dvcmQiOiJzYW0xMjM0In0.H3awAOszz5pQReXIFQtC6wxk0kfwlOjtXFh9QAzut8c\"\n}\n</code></pre> <pre><code>sequenceDiagram\n    autonumber\n    actor Samuel\n    Samuel-&gt;&gt;+App: POST /registrar\n    App-&gt;&gt;+Postgres: SELECT * FROM users WHERE email = Samuel.email\n    alt email j\u00e1 existe\n      Postgres--&gt;&gt;App: 409 Conflict\n      App--&gt;&gt;Samuel: 409 Conflict\n    else email n\u00e3o existe\n      App-&gt;&gt;Postgres: INSERT user(hash_password)\n      App-&gt;&gt;App: gera JWT\n      App--&gt;&gt;-Samuel: 201 Created + { jwt }\n    end</code></pre> <p>Nota: Armazenamos apenas o hash da senha, nunca o texto claro.</p>"},{"location":"projeto/main/#autenticacao-de-usuario","title":"Autentica\u00e7\u00e3o de Usu\u00e1rio","text":"<pre><code>POST /login\nContent-Type: application/json\n</code></pre> <p>Request</p> <pre><code>{\n  \"email\": \"samueljcc@al.insper.edu.br\",\n  \"senha\": \"sam1234\"\n}\n</code></pre> <p>Response (200)</p> <pre><code>{\n  \"jwt\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6InNhbXVlbGpjY0BhbC5pbnNwZXIuZWR1LmJyIiwicGFzc3dvcmQiOiJzYW0xMjM0In0.H3awAOszz5pQReXIFQtC6wxk0kfwlOjtXFh9QAzut8c\"\n}\n</code></pre> <pre><code>sequenceDiagram\n  autonumber\n  actor Samuel\n  participant App\n  participant Postgres\n\n  Samuel-&gt;&gt;+App: POST /login\n  App-&gt;&gt;+Postgres: SELECT hash_password FROM users WHERE email = Samuel.email\n\n  alt usu\u00e1rio n\u00e3o encontrado ou senha inv\u00e1lida\n    Postgres--&gt;&gt;App: (nenhum registro)     &lt;!-- retorna sem desativar Postgres --&gt;\n    App--&gt;&gt;Samuel: 401 Unauthorized         &lt;!-- retorna sem desativar App --&gt;\n  else credenciais v\u00e1lidas\n    Postgres--&gt;&gt;App: hash correto\n    App-&gt;&gt;App: gera JWT\n    App--&gt;&gt;Samuel: 200 OK + { jwt }\n  end\n\n  deactivate Postgres\n  deactivate App\n</code></pre>"},{"location":"projeto/main/#consulta-de-dados","title":"Consulta de Dados","text":"<p>GET /consultar (protegido)</p> <p>Header</p> <pre><code>Authorization: Bearer &lt;JWT&gt;\n</code></pre> <p>Response (200) \u2013 exemplo de cota\u00e7\u00f5es USD\u2192BRL e EUR\u2192BRL via scraping:</p> <pre><code>{\n  \"USD_TO_BRL\": 5.632,\n  \"EUR_TO_BRL\": 6.417\n}\n</code></pre> <pre><code>sequenceDiagram\n  autonumber\n  actor Samuel\n  participant App\n  participant Internet\n\n  Samuel-&gt;&gt;+App: GET /consultar (JWT)\n  App-&gt;&gt;App: valida JWT\n\n  alt JWT inv\u00e1lido\n    App--&gt;&gt;Samuel: 403 Forbidden\n  else JWT v\u00e1lido\n    App-&gt;&gt;+Internet: scrap Wise USD\u2192BRL\n    Internet--&gt;&gt;-App: usd_brl\n    App-&gt;&gt;+Internet: scrap Wise EUR\u2192BRL\n    Internet--&gt;&gt;-App: eur_brl\n    App--&gt;&gt;-Samuel: 200 OK + { usd_brl, eur_brl }\n  end\n</code></pre>"},{"location":"projeto/main/#detalhes-do-web-scraping","title":"Detalhes do Web Scraping","text":"<p>Para obter os valores de c\u00e2mbio na Wise, seguimos este processo:</p> <ol> <li> <p>Acesse a p\u00e1gina de convers\u00e3o desejada, por exemplo:</p> </li> <li> <p>D\u00f3lar \u2192 Real: <code>https://wise.com/us/currency-converter/usd-to-brl-rate</code></p> </li> <li> <p>Euro \u2192 Real:  <code>https://wise.com/br/currency-converter/eur-to-brl</code></p> </li> <li> <p>Abra as ferramentas de desenvolvedor do navegador (F12) e utilize o Inspecionar para localizar o elemento que exibe o valor convertido.</p> </li> <li> <p>Ao passar o cursor sobre a caixa de valor no HTML, verificou-se que o elemento \u00e9 um <code>&lt;span&gt;</code> com a classe <code>text-success</code>.</p> </li> <li> <p>No c\u00f3digo Python, usamos Requests para obter o HTML est\u00e1tico da p\u00e1gina e BeautifulSoup para fazer o parse.</p> </li> <li> <p>Com <code>soup.select_one(\"span.text-success\")</code>, capturamos esse elemento. Em seguida:</p> </li> </ol> <pre><code>span = soup.select_one(\"span.text-success\")\nrate_text = span.get_text(strip=True).replace(\",\", \".\")\nvalor = float(rate_text)\n</code></pre> <ol> <li>Adicionamos <code>valor</code> ao dicion\u00e1rio de respostas sob as chaves <code>USD_TO_BRL</code> e <code>EUR_TO_BRL</code>.</li> </ol> <p>Este m\u00e9todo se aplica a qualquer moeda suportada pelo conversor da Wise, bastando ajustar a URL e reutilizar a mesma l\u00f3gica de sele\u00e7\u00e3o da classe <code>text-success</code>.</p>"},{"location":"projeto/main/#como-executar-etapa-1","title":"Como Executar (Etapa\u00a01)","text":""},{"location":"projeto/main/#estrutura-de-diretorios","title":"Estrutura de Diret\u00f3rios","text":"<pre><code>./\n\u251c\u2500\u2500 app.py\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 sql/\n\u2502   \u2514\u2500\u2500 users.sql\n\u251c\u2500\u2500 models/\n\u2502   \u2514\u2500\u2500 login_schema.py\n\u2502   \u2514\u2500\u2500 register_user_schema.py\n\u2502   \u2514\u2500\u2500 user_schema.py\n\u251c\u2500\u2500 Dockerfile        # para a aplica\u00e7\u00e3o FastAPI\n\u251c\u2500\u2500 Dockerfile-db     # para o Postgres (executa users.sql)\n\u251c\u2500\u2500 compose.yaml      # orquestra app + database\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 .env\n</code></pre>"},{"location":"projeto/main/#docker-hub","title":"Docker Hub","text":"<p>A imagem da API est\u00e1 publicada como:</p> <pre><code>samueljabes/simple_authentication_api:v1.0.1\n</code></pre>"},{"location":"projeto/main/#composeyaml-final","title":"compose.yaml Final","text":"<p>O arquivo <code>compose.yaml</code>, na raiz do projeto, usa apenas imagens do Docker Hub:</p> <pre><code>services:\n  database:\n    build:\n      context: .\n      dockerfile: Dockerfile-db\n    container_name: database\n    restart: always\n    env_file:\n      - .env\n    environment:\n      POSTGRES_USER: ${POSTGRES_USER}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n      POSTGRES_DB: ${POSTGRES_DB}\n\n  app:\n    image: samueljabes/simple_authentication_api:v1.0.1\n    ports:\n      - \"5000:5000\"\n    env_file:\n      - .env\n    depends_on:\n      - database\n</code></pre>"},{"location":"projeto/main/#rodando-localmente","title":"Rodando Localmente","text":"<ol> <li>Configure (ou crie) o arquivo <code>.env</code> na raiz:    <pre><code>POSTGRES_USER=meuusuario\nPOSTGRES_PASSWORD=minhasenha\nPOSTGRES_DB=meubanco\nSECRET_KEY=SUA_CHAVE_JWT\n</code></pre></li> <li>Execute:    <pre><code>docker compose down -v       # limpa containers + volume\ndocker compose pull          # puxa a imagem da API (v1.0.1)\ndocker compose up -d         # sobe app + database\n</code></pre></li> <li>Acesse <code>http://localhost:5000/docs</code> para testar.</li> </ol>"},{"location":"projeto/main/#variaveis-de-ambiente","title":"Vari\u00e1veis de Ambiente","text":"<ul> <li><code>POSTGRES_USER</code>, <code>POSTGRES_PASSWORD</code>, <code>POSTGRES_DB</code>: credenciais do banco.</li> <li><code>POSTGRES_HOST</code> e <code>POSTGRES_PORT</code> n\u00e3o s\u00e3o necess\u00e1rios no <code>compose.yaml</code> final, pois usamos a mesma stack.</li> <li><code>SECRET_KEY</code>: chave para assinar JWT.</li> </ul> <p>Nota de Seguran\u00e7a: Em produ\u00e7\u00e3o, n\u00e3o exponha portas de banco e n\u00e3o inclua credenciais no reposit\u00f3rio.</p>"},{"location":"projeto/main/#link-docker-hub","title":"Link Docker Hub","text":"<p>https://hub.docker.com/r/samueljabes/simple_authentication_api</p>"},{"location":"projeto/main/#publicacao-no-docker-hub","title":"Publica\u00e7\u00e3o no Docker Hub","text":"<p>Para publicar a imagem com a tag <code>latest</code>: <pre><code># Autentica no Docker Hub\ndocker login\n\n# Build e push da tag latest\ndocker build -t samueljabes/simple_authentication_api:latest .\ndocker push samueljabes/simple_authentication_api:latest\n</code></pre></p> <p>Para criar e publicar uma nova tag <code>v1.0.1</code> a partir da imagem <code>latest</code>: <pre><code># Retag da imagem latest para v1.0.1\ndocker tag samueljabes/simple_authentication_api:latest samueljabes/simple_authentication_api:v1.0.1\n\n# Push da nova tag\ndocker push samueljabes/simple_authentication_api:v1.0.1\n</code></pre></p> <p>Para executar localmente usando a tag <code>v1.0.1</code>: <pre><code># Puxa a imagem v1.0.1 do Docker Hub\ndocker pull samueljabes/simple_authentication_api:v1.0.1\n\ndocker compose pull\n\ndocker compose up -d\n</code></pre></p>"},{"location":"projeto/main/#screenshots","title":"Screenshots","text":""},{"location":"projeto/main/#tela-de-registro-de-usuario","title":"Tela de Registro de Usu\u00e1rio","text":"<p> Formulario de registro com payload e resposta de JWT.</p>"},{"location":"projeto/main/#tela-de-login-de-usuario","title":"Tela de Login de Usu\u00e1rio","text":"<p> Formulario de login exibindo o campo de email, senha e resposta de JWT.</p>"},{"location":"projeto/main/#tela-de-consulta-protegida","title":"Tela de Consulta Protegida","text":"<p> Endpoint <code>/consultar</code> solicitando o token JWT e retornando as cota\u00e7\u00f5es.</p>"},{"location":"projeto/main/#video-de-demonstracao","title":"V\u00eddeo de Demonstra\u00e7\u00e3o","text":"<p>Clique na imagem acima para assistir ao v\u00eddeo demonstrando o fluxo de registro, login e consulta.</p>"},{"location":"roteiro1/main/","title":"Roteiro 1 - Cloud Computing","text":""},{"location":"roteiro1/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este roteiro tem como principais objetivos:</p> <ul> <li>Entender os conceitos b\u00e1sicos sobre uma plataforma de gerenciamento de hardware</li> <li>Introduzir conceitos b\u00e1sicos sobre redes de computadores</li> </ul> <p>O Metal-as-a-Service (MaaS) \u00e9 uma solu\u00e7\u00e3o de gerenciamento de infraestrutura que trata servidores f\u00edsicos como m\u00e1quinas virtuais na nuvem. Ele permite provisionar, gerenciar e controlar servidores f\u00edsicos atrav\u00e9s de uma interface web amig\u00e1vel, tornando poss\u00edvel implantar sistemas operacionais rapidamente e gerenciar infraestruturas complexas de forma centralizada.</p>"},{"location":"roteiro1/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Realizar a leitura sobre o MaaS: [https://maas.io/]</li> <li>Familiaridade b\u00e1sica com conceitos de redes e virtualiza\u00e7\u00e3o</li> </ul>"},{"location":"roteiro1/main/#material-do-kit","title":"Material do Kit","text":"<p>O grupo contar\u00e1 com os seguintes itens:</p> <ul> <li>1 NUC (main) com 10GB e 1 SSD (120GB)</li> <li>1 NUC (server1) com 12GB e 1 SSD (120GB)</li> <li>1 NUC (server2) com 16GB e 2 SSD (120GB+120GB)</li> <li>3 NUCs (server3, server4 e server5) com 32GB e 2 SSD (120GB+120GB)</li> <li>1 Switch DLink DSG-1210-28 de 28 portas</li> <li>1 Roteador TP-Link TL-R470T+</li> </ul>"},{"location":"roteiro1/main/#configuracao-de-rede","title":"Configura\u00e7\u00e3o de Rede","text":"<p>Cada grupo tem \u00e0 disposi\u00e7\u00e3o um ponto de rede (cabo preto) com sa\u00edda para a rede interna da faculdade, e cada kit possui um IP de entrada que pode ser verificado no dashboard do roteador.</p>"},{"location":"roteiro1/main/#politica-de-senhas","title":"Pol\u00edtica de Senhas","text":"<p>Todas as senhas do sistema devem seguir o crit\u00e9rio:</p> <ul> <li>Utilizar a palavra 'cloud' + a letra do kit min\u00fascula</li> <li>Por exemplo: 'cloudz' para o kit Z</li> <li>Usar a mesma senha para todos os servi\u00e7os que exigem cadastramento</li> <li>N\u00c3O alterar nenhuma senha que j\u00e1 esteja pr\u00e9-cadastrada</li> </ul> <p>Para o nosso caso, as senhas eram <code>cloudm</code>.</p>"},{"location":"roteiro1/main/#parte-1-infraestrutura","title":"Parte 1: Infraestrutura","text":""},{"location":"roteiro1/main/#instalando-o-ubuntu","title":"Instalando o Ubuntu","text":"<p>Procure tutoriais de como instalar o Sistema Operacional Ubuntu server, utilize um pen drive para baixar a imagem e criar um pendrive para boot da instalacao.</p> <ul> <li>Instale o Ubuntu Server 22.04 LTS na NUC main:<ul> <li>hostname: main</li> <li>login: cloud</li> <li>senha: (cloud + letra do kit)</li> <li>IP fixo: 172.16.0.3</li> <li>Name Servers (DNS): 172.20.129.131</li> </ul> </li> </ul>"},{"location":"roteiro1/main/#instalando-o-maas","title":"Instalando o MaaS","text":"<ul> <li>O MAAS possui diversas vers\u00f5es, iremos utilizar a \"stable\" 3.5.3 link para visualizar o time line</li> <li>Verifique se consegue pingar '8.8.8.8'. Se n\u00e3o conseguir, descubra como rotear os pacotes corretamente.</li> <li>Verifique se consegue pingar 'www.google.com'. Se n\u00e3o conseguir, descubra como resolver as urls corretamente.</li> <li> <p><code>$ sudo apt update &amp;&amp; sudo apt upgrade -y</code></p> </li> <li> <p><code>$ sudo snap install maas --channel=3.5/stable</code></p> </li> <li> <p><code>$ sudo snap install maas-test-db</code></p> </li> </ul> <p>Para acessar nossa m\u00e1quina remotamente, fazemos o acesso utilizando o ssh.</p> <p><code>ssh cloud@172.16.0.3</code></p>"},{"location":"roteiro1/main/#configurando-o-maas","title":"Configurando o MaaS","text":"<ul> <li>Inicializando o MaaS:<ul> <li><code>$ sudo maas init region+rack --maas-url http://172.16.0.3:5240/MAAS --database-uri maas-test-db:///</code></li> <li><code>$ sudo maas createadmin</code></li> <li>use o login cloud</li> <li>use a senha padr\u00e3o da disciplina</li> <li>deixe a chave vazia</li> </ul> </li> <li>Gerando um par de chaves para autentica\u00e7\u00e3o.<ul> <li><code>$ ssh-keygen -t rsa</code></li> <li>use senha vazia dessa vez</li> <li><code>$ cat ./.ssh/id_rsa.pub</code></li> <li>copie a chave gerada</li> </ul> </li> </ul> <p>Primeiramente, precisamos entender onde o servi\u00e7o est\u00e1 rodando e fazer login.</p> <ol> <li> <p>Configure um DNS Forwarder com o DNS do Insper (DNS Externo que o seu roteador enxerga)</p> <ul> <li>Acesse <code>Settings &gt; DNS</code></li> <li>Coloque o DNS do Insper: <code>172.20.129.131</code></li> </ul> </li> <li> <p>Importe as imagens do Ubuntu</p> <ul> <li>Em <code>Configuration &gt; Images</code></li> <li>Selecione Ubuntu 22.04 LTS com arquitetura amd64</li> <li>Selecione Ubuntu 20.04 LTS com arquitetura amd64 (clique em \"Update Selection\")</li> <li>Clique em \"Continue\" sem mexer em \"Other Images\"</li> <li>Finalize com \"Save and Finish Setup\"</li> </ul> </li> <li> <p>Fa\u00e7a o upload da chave SSH</p> <ul> <li>Copie a chave p\u00fablica do seu terminal SSH</li> <li>Inclua todo o conte\u00fado, desde <code>ssh-rsa</code> at\u00e9 o final com <code>cloud@main</code></li> <li>Em Source, escolha \"Upload\"</li> </ul> </li> <li> <p>Configure os par\u00e2metros do kernel</p> <ul> <li>Em <code>Settings &gt; General</code></li> <li>Global Kernel Parameters: <code>net.ifnames=0</code> (sem espa\u00e7os)</li> </ul> </li> </ol>"},{"location":"roteiro1/main/#configuracao-do-dhcp","title":"Configura\u00e7\u00e3o do DHCP","text":"<ol> <li> <p>Habilite o DHCP na subrede pelo MaaS Controller</p> <ul> <li>Acesse <code>Subnets</code> no dashboard</li> <li>Clique em <code>VLAN</code> em \"untagged\"</li> <li>Selecione \"Configure DHCP\"</li> <li>Selecione o Rack controller como \"main\"</li> <li>Coloque a subnet criada (172.16.0.0/20)</li> <li>Clique em \"Configure DHCP\"</li> <li>Confirme clicando em \"OK\"</li> </ul> </li> <li> <p>Altere o Reserved Range</p> <ul> <li>Configure para iniciar em <code>172.16.11.1</code> e terminar em <code>172.16.14.255</code></li> <li>Este range ficou configurado como din\u00e2mico</li> </ul> </li> <li> <p>Configure o DNS da subnet</p> <ul> <li>Mantenha apontando para o DNS do Insper</li> <li>Acesse <code>Subnet &gt; IP subnet &gt; Edit</code></li> </ul> </li> <li> <p>Desabilite o DHCP no roteador</p> <ul> <li>Acesse o IP do roteador: <code>172.16.0.1</code></li> <li>Navegue at\u00e9 <code>Network &gt; LAN &gt; DHCP Server</code></li> <li>Altere o status para \"Disable\"</li> <li>Salve as altera\u00e7\u00f5es</li> </ul> </li> </ol>"},{"location":"roteiro1/main/#verificacao-da-saude-do-maas","title":"Verifica\u00e7\u00e3o da Sa\u00fade do MaaS","text":"<p>Confirme a sa\u00fade do sistema MaaS:</p> <ol> <li>Visite a p\u00e1gina \"Controllers\" na interface web (dashboard)</li> <li>Selecione o nome do controlador</li> <li>Certifique-se de que a p\u00e1gina mostre uma marca de sele\u00e7\u00e3o verde ao lado dos itens 'regiond' at\u00e9 'dhcpd'</li> </ol> <p></p>"},{"location":"roteiro1/main/#comissionamento-de-servidores","title":"Comissionamento de Servidores","text":"<ol> <li> <p>Cadastre os hosts (machines) dispon\u00edveis, do server1 at\u00e9 server5</p> <ul> <li>Altere a op\u00e7\u00e3o Power Type para Intel AMT e preencha conforme abaixo:</li> <li>MacAddress: utilize o que foi anotado anteriormente</li> <li>Senha: <code>CloudComp6s!</code></li> <li>IP do AMT: <code>172.16.15.X</code> (sendo X o id do server, por exemplo server1 = 172.16.15.1)</li> </ul> </li> <li> <p>As NUCs ir\u00e3o comissionar automaticamente via boot PXE na rede</p> </li> <li> <p>Verifica\u00e7\u00e3o das caracter\u00edsticas de hardware:</p> <ul> <li>Server1: Caracter\u00edsticas a serem observadas</li> <li>Server2: 248,1GB no storage e 32GB de RAM</li> <li>Server3: 248,1GB no storage e 31GB de RAM</li> <li>Server4: 240,1GB no storage e 32GB de RAM</li> <li>Server5: 240,1GB no storage e 32GB de RAM</li> </ul> </li> <li> <p>Confirme que todos os n\u00f3s aparecem com o status Ready</p> <ul> <li>Verifique se as caracter\u00edsticas de hardware (cpu, mem\u00f3ria, SSD e rede) foram detectadas corretamente</li> </ul> </li> </ol>"},{"location":"roteiro1/main/#adicionando-o-roteador-como-device","title":"Adicionando o Roteador como Device","text":"<ol> <li>Acesse <code>Devices &gt; Add Device</code></li> <li>Configure:<ul> <li>Device Name: Roteador</li> <li>MAC Address: utilize o endere\u00e7o do roteador</li> <li>Para encontrar o MAC Address acesse <code>Dashboard do Roteador &gt; Network &gt; MAC &gt; Current MAC Address</code> (na linha de LAN)</li> </ul> </li> <li>Clique em \"Save device\"</li> </ol>"},{"location":"roteiro1/main/#criando-ovs-bridge","title":"Criando OVS Bridge","text":"<p>Uma Open vSwitch (OVS) bridge reduz a necessidade de duas interfaces de rede f\u00edsicas.</p> <p>Para cada servidor, execute este procedimento:</p> <ol> <li>Acesse <code>Machines</code></li> <li>Selecione cada servidor individualmente</li> <li>Navegue at\u00e9 <code>Network</code></li> <li>Selecione a interface <code>eth0</code></li> <li>Clique em \"Create bridge\"</li> <li>Mude o nome para <code>br-ex</code></li> <li>Coloque Bride Type como <code>Open vSwitch (OVS)</code></li> <li>Sete o <code>Auto-Assign</code></li> <li>Clique em \"Save interface\"</li> </ol> <p>O nome da ponte ser\u00e1 referenciado em outras partes dos roteiros. Neste exemplo de nuvem, utilizamos uma \u00fanica VLAN n\u00e3o etiquetada.</p> <p></p>"},{"location":"roteiro1/main/#configurando-acesso-remoto","title":"Configurando Acesso Remoto","text":"<p>Vamos realizar um NAT para permitir o acesso externo da \"Rede Wi-fi Insper\" ao servidor MAIN.</p> <ol> <li> <p>Crie uma regra NAT para acesso SSH:</p> <ul> <li>Acesse <code>Dashboard do roteador &gt; Transmission &gt; NAT &gt; Virtual Servers &gt; Add</code></li> <li>Configure portas interna e externa como 22</li> <li>O IP \u00e9 o da NUC main: <code>172.16.0.3</code></li> <li>A rede <code>0.0.0.0/0</code> representa \"libere o acesso sempre\"</li> </ul> </li> <li> <p>Libere o acesso ao gerenciamento remoto do roteador:</p> <ul> <li>Acesse <code>Dashboard do Roteador &gt; System Tools &gt; Admin Setup &gt; Remote Management</code></li> <li>Configure o IP como <code>0.0.0.0/0</code></li> <li>Status: Enable</li> </ul> </li> <li> <p>Registre os IPs importantes:</p> <ul> <li>IP FIXO DO ROTEADOR (EXTERNO): <code>10.103.1.22</code> (IP que o Insper enxerga)</li> <li>IP INTERNO DO ROTEADOR: <code>172.16.0.1</code></li> </ul> </li> <li> <p>Crie uma regra NAT para o MaaS:</p> <ul> <li>Configure de forma similar ao SSH, mas usando a porta 5240</li> <li>IP continua sendo o da NUC main: <code>172.16.0.3</code></li> </ul> </li> </ol>"},{"location":"roteiro1/main/#enderecos-ip-relevantes","title":"Endere\u00e7os IP Relevantes","text":"<p>Para refer\u00eancia e configura\u00e7\u00f5es futuras, registre os seguintes endere\u00e7os:</p> Descri\u00e7\u00e3o Endere\u00e7o Observa\u00e7\u00e3o IP externo do roteador <code>10.103.1.22</code> IP fixo vis\u00edvel pela rede do Insper IP interno do roteador <code>172.16.0.1</code> Gateway da rede interna Porta do servi\u00e7o MaaS <code>5240</code> Porta fixa do servi\u00e7o IP da NUC main <code>172.16.0.3</code> Servidor principal <p>Ap\u00f3s estas configura\u00e7\u00f5es, \u00e9 poss\u00edvel acessar tanto o roteador quanto o servi\u00e7o MaaS a partir de qualquer ponto conectado \u00e0 rede do Insper, eliminando a necessidade de conex\u00e3o f\u00edsica direta. O roteador atua como intermedi\u00e1rio, redirecionando as requisi\u00e7\u00f5es externas para os servi\u00e7os internos apropriados.</p> <p>Agora \u00e9 poss\u00edvel acessar o roteador de qualquer lugar do Insper pelo seu IP externo.</p>"},{"location":"roteiro1/main/#parte-2-aplicacao","title":"Parte 2: Aplica\u00e7\u00e3o","text":""},{"location":"roteiro1/main/#django-em-nuvem-bare-metal","title":"Django em Nuvem Bare-Metal","text":""},{"location":"roteiro1/main/#ajuste-no-dns-server","title":"Ajuste no DNS Server","text":"<p>Antes de come\u00e7ar, realize um pequeno ajuste no DNS server:</p> <ol> <li>Dentro da aba Subnets, clique na subnet <code>172.16.0.0/20</code></li> <li>Edite a Subnet summary colocando o DNS do Insper: <code>172.20.129.131</code></li> </ol>"},{"location":"roteiro1/main/#implantacao-do-banco-de-dados-postgresql","title":"Implanta\u00e7\u00e3o do Banco de Dados (PostgreSQL)","text":"<ol> <li> <p>Acesse o Dashboard do MaaS e realize o deploy do Ubuntu 22.04 no server1</p> <ul> <li>Navegue at\u00e9 <code>Machines &gt; Server1 &gt; Actions &gt; Deploy &gt; Deploy Machine</code></li> </ul> </li> <li> <p>Acesse o terminal do server1 via SSH:    <pre><code>ssh ubuntu@172.16.15.13  # IP_DO_SERVER1\n</code></pre></p> </li> <li> <p>Instale o PostgreSQL:    <pre><code>sudo apt update\nsudo apt install postgresql postgresql-contrib -y\n</code></pre></p> </li> <li> <p>Crie um usu\u00e1rio para a aplica\u00e7\u00e3o:    <pre><code>sudo su - postgres\ncreateuser -s cloud -W\n# Use a senha: cloud\n</code></pre></p> </li> <li> <p>Crie um database para a aplica\u00e7\u00e3o:    <pre><code>createdb -O cloud tasks\n</code></pre></p> </li> <li> <p>Configure o PostgreSQL para aceitar conex\u00f5es remotas:    <pre><code>nano /etc/postgresql/16/main/postgresql.conf\n</code></pre></p> <ul> <li>Remova o coment\u00e1rio e substitua a linha para aceitar conex\u00f5es remotas:    <pre><code>listen_addresses = '*'\n</code></pre></li> </ul> </li> <li> <p>Configure o acesso:    <pre><code>nano /etc/postgresql/16/main/pg_hba.conf\n</code></pre></p> <ul> <li>Adicione a linha que libera m\u00e1quinas dentro da subnet do kit:    <pre><code>host    all    all    172.16.0.0/20    trust\n</code></pre></li> </ul> </li> <li> <p>Saia do usu\u00e1rio postgres com o comando <code>exit</code></p> </li> <li> <p>Libere o firewall:    <pre><code>sudo ufw allow 5432/tcp\n</code></pre></p> </li> <li> <p>Reinicie o servi\u00e7o:     <pre><code>sudo systemctl restart postgresql\n</code></pre></p> </li> </ol> <p>Tarefa-1</p> <p>Estude os comandos ping, ifconfig, systemctl, telnet, ufw, curl, wget e journalctl. Com estes comandos apresente prints das Telas  que provam que o banco de dados est\u00e1:</p> <pre><code>1. Funcionando e seu Status est\u00e1 como \"Ativo\" para o Sistema Operacional\n2. Acessivel na pr\u00f3pria maquina na qual ele foi implantado.\n3. Acessivel a partir de uma conex\u00e3o vinda da m\u00e1quina MAIN.\n4. Em qual porta este servi\u00e7o est\u00e1 funcionando.\n</code></pre>"},{"location":"roteiro1/main/#1-funcionando-e-seu-status-esta-como-ativo-para-o-sistema-operacional","title":"1. Funcionando e seu Status est\u00e1 como \"Ativo\" para o Sistema Operacional.","text":""},{"location":"roteiro1/main/#2-acessivel-na-propria-maquina-na-qual-ele-foi-implantado","title":"2. Acessivel na pr\u00f3pria maquina na qual ele foi implantado.","text":""},{"location":"roteiro1/main/#3-acessivel-a-partir-de-uma-conexao-vinda-da-maquina-main","title":"3. Acessivel a partir de uma conex\u00e3o vinda da m\u00e1quina MAIN.","text":""},{"location":"roteiro1/main/#4-em-qual-porta-este-servico-esta-funcionando","title":"4. Em qual porta este servi\u00e7o est\u00e1 funcionando.","text":""},{"location":"roteiro1/main/#implantacao-da-aplicacao-django","title":"Implanta\u00e7\u00e3o da Aplica\u00e7\u00e3o Django","text":"<ol> <li> <p>Volte ao MaaS e solicite uma m\u00e1quina via CLI:    <pre><code>maas login cloud http://172.16.0.3:5240/MAAS/\n</code></pre></p> <ul> <li>Busque o token no dashboard dentro das configura\u00e7\u00f5es do usu\u00e1rio: <code>Cloud &gt; API Keys</code></li> </ul> </li> <li> <p>Solicite a reserva da m\u00e1quina para o MaaS:    <pre><code>maas cloud machines allocate name=server2\n</code></pre></p> <ul> <li>Anote o system_id do JSON resultante (no nosso caso: <code>ew8g34</code>)</li> </ul> </li> <li> <p>Realize o deploy via linha de comando:    <pre><code>maas cloud machine deploy ew8g34\n</code></pre></p> </li> <li> <p>Ap\u00f3s o deploy, acesse o servidor via SSH (IP: <code>172.16.15.14</code>):    <pre><code>ssh ubuntu@172.16.15.14\n</code></pre></p> </li> <li> <p>Clone o reposit\u00f3rio da aplica\u00e7\u00e3o:    <pre><code>git clone https://github.com/raulikeda/tasks.git\ncd tasks/\n</code></pre></p> </li> <li> <p>Configure o banco de dados:</p> <ul> <li>Edite o arquivo de configura\u00e7\u00e3o do Django:    <pre><code>nano portfolio/settings.py\n</code></pre></li> <li>Altere a configura\u00e7\u00e3o do banco de dados para apontar para o IP do server1:    <pre><code>DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql',\n        'NAME': 'nome_do_banco',\n        'USER': 'usuario',\n        'PASSWORD': 'senha',\n        'HOST': '172.16.15.13',  # IP do server1\n        'PORT': '5432',\n    }\n}\n</code></pre></li> <li>ou abra o arquivo     <pre><code>nano /etc/hosts\n</code></pre>    E adicione o endere\u00e7amento do server1 ao seu IP.</li> </ul> </li> <li> <p>Execute o script de instala\u00e7\u00e3o:    <pre><code>./install.sh\n</code></pre></p> </li> <li> <p>Reinicie o servidor:    <pre><code>sudo reboot\n</code></pre></p> </li> <li> <p>Teste o acesso ao servi\u00e7o:    <pre><code>wget http://172.16.15.14:8080/admin/\n</code></pre></p> </li> </ol> <p></p>"},{"location":"roteiro1/main/#criando-um-tunel-ssh-para-acesso-externo","title":"Criando um T\u00fanel SSH para Acesso Externo","text":"<p>Para acessar o servi\u00e7o no seu navegador:</p> <ol> <li> <p>Desconecte do SSH do MaaS com o comando <code>exit</code></p> </li> <li> <p>Reconecte criando um t\u00fanel SSH:    <pre><code>ssh cloud@10.103.1.22 -L 8001:172.16.15.7:8080\n</code></pre></p> </li> </ol> <p>Este comando cria um t\u00fanel do servi\u00e7o do server2 na porta 8080 para o seu localhost na porta 8001.</p> <ol> <li>Acesse no navegador: <code>http://localhost:8001/admin/</code></li> <li>Login Django: <code>cloud</code></li> <li>Senha Django: <code>cloud</code></li> </ol> <p></p> <p>Um t\u00fanel SSH \u00e9 uma conex\u00e3o segura que permite redirecionar dados de uma m\u00e1quina remota para sua m\u00e1quina local. Ele funciona como um \"canal secreto\" criptografado, protegendo a comunica\u00e7\u00e3o contra intercepta\u00e7\u00f5es.</p> <p>Tarefa-2</p> <p>De um print das Telas abaixo:</p> <pre><code>1. Do Dashboard do **MAAS** com as m\u00e1quinas.\n2. Da aba images, com as imagens sincronizadas.\n3. Da Aba de cada maquina(5x) mostrando os testes de hardware e commissioning com Status \"OK\"\n</code></pre>"},{"location":"roteiro1/main/#1-do-dashboard-do-maas-com-as-maquinas","title":"1. Do Dashboard do MAAS com as m\u00e1quinas.","text":""},{"location":"roteiro1/main/#2-da-aba-images-com-as-imagens-sincronizadas","title":"2. Da aba images, com as imagens sincronizadas.","text":""},{"location":"roteiro1/main/#3-da-aba-de-cada-maquina5x-mostrando-os-testes-de-hardware-e-commissioning-com-status-ok","title":"3. Da Aba de cada maquina(5x) mostrando os testes de hardware e commissioning com Status \"OK\"","text":""},{"location":"roteiro1/main/#implantacao-automatizada-com-ansible","title":"Implanta\u00e7\u00e3o Automatizada com Ansible","text":"<p>Para aumentar a disponibilidade da aplica\u00e7\u00e3o, vamos implementar uma segunda inst\u00e2ncia da aplica\u00e7\u00e3o Django:</p> <ol> <li> <p>Fa\u00e7a o deploy do Ubuntu 22.04 no server3 via dashboard do MaaS</p> </li> <li> <p>No SSH do main, instale o Ansible:    <pre><code>sudo apt install ansible\nwget https://raw.githubusercontent.com/raulikeda/tasks/master/tasks-install-playbook.yaml\n</code></pre></p> </li> <li> <p>Execute o playbook do Ansible:    <pre><code>ansible-playbook tasks-install-playbook.yaml --extra-vars server=172.16.15.15  # IP do server3\n</code></pre></p> </li> </ol> <p>A diferen\u00e7a entre a instala\u00e7\u00e3o manual e com Ansible \u00e9 que manualmente precisamos pedir uma m\u00e1quina ao MaaS, solicitar uma reserva, deployar e instalar via script, o que \u00e9 trabalhoso e n\u00e3o automatizado. Com o Ansible, realizamos a instala\u00e7\u00e3o de forma autom\u00e1tica, pois ele j\u00e1 \u00e9 um gerenciador de deploy - basta fornecer o arquivo YAML com os requisitos.</p>"},{"location":"roteiro1/main/#balanceamento-de-carga-com-proxy-reverso","title":"Balanceamento de Carga com Proxy Reverso","text":"<p>Para criar um ponto \u00fanico de entrada e distribuir a carga entre os servidores, vamos implementar um proxy reverso com Nginx:</p> <ol> <li> <p>Fa\u00e7a o deploy do Ubuntu no server4 via dashboard do MaaS</p> </li> <li> <p>Acesse o server4 via SSH e instale o Nginx:    <pre><code>sudo apt-get update\nsudo apt-get install nginx\n</code></pre></p> </li> <li> <p>Configure o m\u00f3dulo upstream:    <pre><code>sudo nano /etc/nginx/sites-available/default\n</code></pre></p> </li> <li> <p>Adicione a configura\u00e7\u00e3o de balanceamento de carga:    <pre><code>upstream backend {\n    server 172.16.15.7:8080;  # IP do server2\n    server 172.16.15.15:8080; # IP do server3\n}\n\nserver {\n    location / {\n        proxy_pass http://backend;\n    }\n}\n</code></pre></p> </li> <li> <p>Reinicie o Nginx:    <pre><code>sudo service nginx restart\n</code></pre></p> </li> <li> <p>Modifique a mensagem de cada servidor Django para identifica\u00e7\u00e3o:</p> </li> <li>Edite o arquivo <code>tasks/views.py</code> em cada servidor:    <pre><code>nano tasks/views.py\n</code></pre></li> <li> <p>Altere a mensagem para incluir o nome do servidor:    <pre><code>from django.shortcuts import render\nfrom django.http import HttpResponse\n\ndef index(request):\n    return HttpResponse(\"Hello, world. You're at the tasks index (on server2).\")  # ou server3\n</code></pre></p> </li> <li> <p>Edite o arquivo <code>urls.py</code> para customizar o path:    <pre><code>urlpatterns = [path('', views.index, name='index'),]\n</code></pre></p> </li> <li> <p>Teste o acesso ao proxy reverso, verificando que ele alterna entre os servidores.</p> </li> </ol> <p>Tarefa-5</p> <p>Teste o acesso, caso esteja tudo certo, fa\u00e7a a tarefa abaixo:</p> <pre><code>1. De um print da tela do Dashboard do MAAS com as 4 Maquinas e seus respectivos IPs.\n2. Altere o conte\u00fado da mensagem contida na fun\u00e7\u00e3o `index` do arquivo `tasks/views.py` de cada server para distinguir ambos os servers. \n3. Fa\u00e7a um `GET request` para o path que voce criou em urls.py para o Nginx e tire 2 prints das respostas de cada request, provando que voce est\u00e1 conectado ao server 4, que \u00e9 o Proxy Reverso e que ele bate cada vez em um server diferente server2 e server3.\n</code></pre>"},{"location":"roteiro1/main/#1-de-um-print-da-tela-do-dashboard-do-maas-com-as-4-maquinas-e-seus-respectivos-ips","title":"1. De um print da tela do Dashboard do MAAS com as 4 Maquinas e seus respectivos IPs.","text":""},{"location":"roteiro1/main/#2-altere-o-conteudo-da-mensagem-contida-na-funcao-index-do-arquivo-tasksviewspy-de-cada-server-para-distinguir-ambos-os-servers","title":"2. Altere o conte\u00fado da mensagem contida na fun\u00e7\u00e3o <code>index</code> do arquivo <code>tasks/views.py</code> de cada server para distinguir ambos os servers.","text":""},{"location":"roteiro1/main/#3-faca-um-get-request-para-o-path-que-voce-criou-em-urlspy-para-o-nginx-e-tire-2-prints-das-respostas-de-cada-request-provando-que-voce-esta-conectado-ao-server-4-que-e-o-proxy-reverso-e-que-ele-bate-cada-vez-em-um-server-diferente-server2-e-server3","title":"3. Fa\u00e7a um <code>GET request</code> para o path que voce criou em urls.py para o Nginx e tire 2 prints das respostas de cada request, provando que voce est\u00e1 conectado ao server 4, que \u00e9 o Proxy Reverso e que ele bate cada vez em um server diferente server2 e server3.","text":""},{"location":"roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>Neste roteiro, configuramos com sucesso:</p> <ol> <li>Um controlador MaaS para gerenciar nossa infraestrutura bare-metal</li> <li>Uma rede com DHCP controlado pelo MaaS</li> <li>Um servidor de banco de dados PostgreSQL</li> <li>Duas inst\u00e2ncias de uma aplica\u00e7\u00e3o Django</li> <li>Um balanceador de carga com Nginx para distribuir o tr\u00e1fego</li> </ol>"},{"location":"roteiro2/main/","title":"Roteiro 2 - Juju","text":""},{"location":"roteiro2/main/#deployment-orchestration","title":"Deployment Orchestration","text":""},{"location":"roteiro2/main/#criando-infraestrutura-para-deploy-com-juju","title":"Criando infraestrutura para deploy com Juju","text":"<p>O Ansible \u00e9 eficaz para gerenciar instala\u00e7\u00e3o e configura\u00e7\u00e3o de n\u00f3s j\u00e1 provisionados, mas n\u00e3o realiza provisionamento direto com o MAAS (gerenciador de Bare Metal). Para montar nossa Cloud Privada, vamos utilizar o Juju, que se integra diretamente com o MAAS.</p>"},{"location":"roteiro2/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Verifique se todas as m\u00e1quinas (server1, server2, server3, server4 e server5) est\u00e3o com status Ready no MAAS.</li> <li>Fa\u00e7a o release das m\u00e1quinas utilizadas anteriormente com Django e Postgres, se necess\u00e1rio.</li> </ul>"},{"location":"roteiro2/main/#instalacao-do-juju","title":"Instala\u00e7\u00e3o do Juju","text":"<p>No n\u00f3 principal (<code>main</code>), execute:</p> <pre><code>sudo snap install juju --channel 3.6\n</code></pre>"},{"location":"roteiro2/main/#verificacao-e-adicao-do-maas-como-provedor","title":"Verifica\u00e7\u00e3o e Adi\u00e7\u00e3o do MAAS como Provedor","text":"<p>Verifique se o MAAS j\u00e1 est\u00e1 listado como provedor:</p> <pre><code>juju clouds\n</code></pre> <p>Caso n\u00e3o esteja, crie o arquivo <code>maas-cloud.yaml</code> com a defini\u00e7\u00e3o do provedor (verifique o endpoint do seu ambiente!):</p> <pre><code>clouds:\n  maas-one:\n    type: maas\n    auth-types: [oauth1]\n    endpoint: http://192.168.0.3:5240/MAAS/\n</code></pre> <p>Adicione a cloud:</p> <pre><code>juju add-cloud --client -f maas-cloud.yaml maas-one\n</code></pre>"},{"location":"roteiro2/main/#adicionando-credenciais-maas","title":"Adicionando credenciais MAAS","text":"<p>Crie o arquivo <code>maas-creds.yaml</code>:</p> <pre><code>credentials:\n  maas-one:\n    anyuser:\n      auth-type: oauth1\n      maas-oauth: &lt;API_KEY&gt;\n</code></pre> <p>Substitua <code>&lt;API_KEY&gt;</code> pela sua chave de acesso do MAAS.</p> <p>Adicione as credenciais:</p> <pre><code>juju add-credential --client -f maas-creds.yaml maas-one\n</code></pre>"},{"location":"roteiro2/main/#criando-o-modelo-openstack","title":"Criando o modelo OpenStack","text":"<pre><code>juju add-model --config default-series=jammy openstack\n</code></pre>"},{"location":"roteiro2/main/#parte-do-app","title":"Parte do App","text":""},{"location":"roteiro2/main/#utilizando-a-infraestrutura-bare-metal-com-o-juju","title":"Utilizando a infraestrutura Bare Metal com o Juju","text":"<p>Vamos utilizar o Juju para fazer o deploy da seguinte arquitetura:</p> <ul> <li>Grafana com Prometheus</li> </ul>"},{"location":"roteiro2/main/#instalando-o-dashboard-do-juju","title":"Instalando o Dashboard do Juju","text":"<p>Instale o dashboard:</p> <pre><code>juju deploy juju-dashboard dashboard --to lxd:0\njuju integrate dashboard controller\njuju expose dashboard\njuju dashboard\n</code></pre> <p>Sa\u00edda esperada:</p> <pre><code>Dashboard for controller \"maas-controller\" is enabled at:\n  http://localhost:31666\nYour login credential is:\n  username: admin\n  password: &lt;senha&gt;\n</code></pre>"},{"location":"roteiro2/main/#acessando-o-dashboard-remotamente","title":"Acessando o dashboard remotamente","text":"<p>Fa\u00e7a um t\u00fanel SSH para acessar o dashboard a partir do seu navegador:</p> <pre><code>ssh cloud@10.103.1.22 -L 31666:172.16.15.18:8080\n</code></pre>"},{"location":"roteiro2/main/#alternando-entre-modelos","title":"Alternando entre modelos","text":"<p>Verifique os modelos existentes:</p> <pre><code>juju models\n</code></pre> <p>Mude para o modelo de aplica\u00e7\u00f5es:</p> <pre><code>juju switch openstack\n</code></pre> <p>Volte para o controlador:</p> <pre><code>juju switch maas-controller:admin/maas\n</code></pre>"},{"location":"roteiro2/main/#deploy-do-grafana-e-prometheus","title":"Deploy do Grafana e Prometheus","text":"<p>O Grafana \u00e9 uma plataforma open-source para visualiza\u00e7\u00e3o de dados. Neste caso, ele ser\u00e1 integrado ao Prometheus, que funcionar\u00e1 como seu banco de dados.</p>"},{"location":"roteiro2/main/#baixando-os-charms","title":"Baixando os charms","text":"<p>Crie uma pasta para os charms:</p> <pre><code>mkdir -p ~/charms\ncd ~/charms\n</code></pre> <p>Baixe os charms:</p> <pre><code>juju download grafana\njuju download prometheus2\n</code></pre>"},{"location":"roteiro2/main/#realizando-o-deploy","title":"Realizando o Deploy","text":"<pre><code>juju deploy ./prometheus2_r60.charm\njuju deploy ./grafana_r69.charm --base ubuntu@20.04\n</code></pre> <p>Acompanhe o status:</p> <pre><code>watch -n 1 --color \"juju status --color\"\n</code></pre>"},{"location":"roteiro2/main/#integracao-do-grafana-com-prometheus","title":"Integra\u00e7\u00e3o do Grafana com Prometheus","text":"<p>Siga a documenta\u00e7\u00e3o oficial do charm do Grafana para integra\u00e7\u00e3o:</p> <pre><code>juju integrate grafana:grafana-source prometheus2:grafana-source\n</code></pre> <p>Acesse o dashboard do Grafana e verifique se o Prometheus est\u00e1 listado como source. Crie um dashboard com uma visualiza\u00e7\u00e3o para confirmar a integra\u00e7\u00e3o.</p>"},{"location":"roteiro2/main/#tarefas","title":"Tarefas","text":"<p>Tarefa</p> <ol> <li>Print do Dashboard do MAAS com as m\u00e1quinas e seus respectivos IPs.</li> <li>Print do comando <code>juju status</code> com o Grafana ativo.</li> <li>Print do Dashboard do Grafana mostrando o Prometheus como source.</li> <li>Prova (print) de acesso ao Dashboard via rede do Insper.</li> <li>Print da tela do Dashboard Juju com as aplica\u00e7\u00f5es em execu\u00e7\u00e3o: <code>http://&lt;IP-Servi\u00e7o&gt;:8080/models/admin/maas</code></li> </ol>"},{"location":"roteiro2/main/#1-print-do-dashboard-do-maas-com-as-maquinas-e-seus-respectivos-ips","title":"1. Print do Dashboard do MAAS com as m\u00e1quinas e seus respectivos IPs.","text":""},{"location":"roteiro2/main/#2-print-do-comando-juju-status-com-o-grafana-ativo","title":"2. Print do comando <code>juju status</code> com o Grafana ativo.","text":""},{"location":"roteiro2/main/#3-print-do-dashboard-do-grafana-mostrando-o-prometheus-como-source","title":"3. Print do Dashboard do Grafana mostrando o Prometheus como source","text":""},{"location":"roteiro2/main/#4-prova-print-de-acesso-ao-dashboard-via-rede-do-insper","title":"4. Prova (print) de acesso ao Dashboard via rede do Insper.","text":""},{"location":"roteiro2/main/#5-print-da-tela-do-dashboard-juju-com-as-aplicacoes-em-execucao-httpip-servico8080modelsadminmaas","title":"5. Print da tela do Dashboard Juju com as aplica\u00e7\u00f5es em execu\u00e7\u00e3o: <code>http://&lt;IP-Servi\u00e7o&gt;:8080/models/admin/maas</code>","text":""},{"location":"roteiro2/main/#_1","title":"Roteiro 2","text":""},{"location":"roteiro2/main/#limpeza-de-ambiente","title":"Limpeza de Ambiente","text":"<p>Execute os comandos abaixo para destruir o ambiente:</p> <pre><code>juju destroy-model openstack\njuju destroy-controller maas-controller\n</code></pre> <p>Em cada servidor:</p> <p>Navegue at\u00e9 <code>Network &gt; Create Bridge</code> e configure com:</p> <ul> <li>Nome: <code>br-ex</code></li> <li>Tipo: <code>OVS</code></li> <li>VLAN: habilitado</li> <li>IP Mode: DHCP</li> </ul>"},{"location":"roteiro3/main/","title":"Roteiro 3 - OpenStack","text":""},{"location":"roteiro3/main/#infra","title":"Infra","text":""},{"location":"roteiro3/main/#criando-a-infraestrutura-nuvem-vm-servidor-virtual-privado-vps","title":"Criando a Infraestrutura (Nuvem VM) \u2013 Servidor Virtual Privado (VPS)","text":"<p>Nesse roteiro vamos instalar um conjunto de aplica\u00e7\u00f5es denominado OpenStack que vai permitir distribuirmos m\u00e1quinas virtuais usando os n\u00f3s dispon\u00edveis no kit.</p> <p>At\u00e9 o momento usamos o MAAS para orquestrar o bare metal e o Juju para cuidar do deployment de aplica\u00e7\u00f5es (por exemplo, Grafana e Prometheus). Agora, vamos utilizar o OpenStack para criar VMs e distribuir os servi\u00e7os em todas as m\u00e1quinas do kit com maior efici\u00eancia.</p> <p>Aten\u00e7\u00e3o</p> <p>Confira se os seus recursos f\u00edsicos seguem, no M\u00cdNIMO, a tabela abaixo. Volte ao dashboard do MAAS e crie as Tags conforme descrito:</p> Node name Tag(s) CPUs NICs RAM (GB) Disks Storage (GB) node1.maas controller 2 1 12.0 1 80.0 node2.maas reserva 2 1 16.0 2 80.0 node3.maas compute 2 1 32.0 2 80.0 node4.maas compute 2 1 32.0 2 80.0 node5.maas compute 2 1 32.0 2 80.0 <p>Antes de come\u00e7ar a instala\u00e7\u00e3o do OpenStack, verifique se o MAAS est\u00e1 configurado corretamente (Bridges, Subnets, Tags etc).</p>"},{"location":"roteiro3/main/#bridge-no-maas","title":"Bridge no MAAS","text":"<p>Verifique se o <code>br-ex</code> est\u00e1 configurado corretamente no MAAS. O <code>br-ex</code> \u00e9 a interface de rede que conecta o OpenStack \u00e0 rede externa. Se n\u00e3o estiver configurado corretamente, o OpenStack n\u00e3o conseguir\u00e1 se comunicar com o mundo exterior.</p> <ol> <li>Acesse o painel do MAAS e v\u00e1 para a se\u00e7\u00e3o de redes.  </li> <li>Verifique se o <code>br-ex</code> est\u00e1 listado e conectado \u00e0 rede correta.  </li> <li>Caso contr\u00e1rio, configure-o antes de prosseguir.</li> </ol> <p>O <code>br-ex</code> deve estar configurado para todos os n\u00f3s.</p>"},{"location":"roteiro3/main/#implantacao-do-openstack","title":"Implanta\u00e7\u00e3o do OpenStack","text":"<p>\u201cSiga\u201d o passo a passo do guia oficial, por\u00e9m n\u00e3o instale nada no server2 (reservado). Altere os comandos para que:</p> <ul> <li>server1 seja o controller </li> <li>server2 seja a reserva </li> <li>server3, server4 e server5 sejam compute</li> </ul> <p>Execute um comando por vez e aguarde a conclus\u00e3o antes de prosseguir: <pre><code>juju status\n</code></pre></p> <p>Esse roteiro foi adaptado ao nosso ambiente. Estude o guia oficial antes de come\u00e7ar:</p> <ul> <li>Documenta\u00e7\u00e3o oficial: Instala\u00e7\u00e3o do OpenStack com Juju</li> </ul>"},{"location":"roteiro3/main/#juju-controller","title":"Juju Controller","text":"<p>Aten\u00e7\u00e3o: apenas se ainda n\u00e3o existir um Juju Controller instalado. Adicione a tag <code>controller</code> na m\u00e1quina server1 e execute: <pre><code>juju bootstrap --bootstrap-series=jammy --constraints tags=controller maas-one maas-controller\n</code></pre></p>"},{"location":"roteiro3/main/#definindo-o-modelo-de-deploy","title":"Definindo o modelo de deploy","text":"<pre><code>juju add-model --config default-series=jammy openstack\njuju switch maas-controller:openstack\n</code></pre> <p>Opcional: instalar o dashboard do Juju: Manage the Juju Dashboard</p>"},{"location":"roteiro3/main/#monitoramento","title":"Monitoramento","text":"<p>Abra um novo terminal e rode:</p> <pre><code>watch -n 2 --color \"juju status --color\"\n</code></pre> <p>o status ser\u00e1 atualizado a cada 2 segundos.</p>"},{"location":"roteiro3/main/#roteiro-atualizado-de-instalacao-do-openstack","title":"Roteiro Atualizado de Instala\u00e7\u00e3o do OpenStack","text":"<p>Em caso de problemas, consulte primeiro a documenta\u00e7\u00e3o oficial.</p> <ol> <li> <p>Instalando o Juju Controller</p> <p>Aten\u00e7\u00e3o: somente se ainda n\u00e3o existir um controlador.</p> <pre><code>juju bootstrap --bootstrap-series=jammy --constraints tags=controller maas-one maas-controller\n</code></pre> </li> <li> <p>Definindo o modelo de deploy</p> <pre><code>juju add-model --config default-series=jammy openstack\njuju switch maas-controller:openstack\n</code></pre> </li> <li> <p>Ceph OSD     Implanta 3 unidades do <code>ceph-osd</code>.     ceph-osd.yaml:</p> <pre><code>ceph-osd:\n  osd-devices: /dev/sda /dev/sdb\n</code></pre> <pre><code>juju deploy -n 3 --channel quincy/stable --config ceph-osd.yaml --constraints tags=compute ceph-osd\n</code></pre> </li> </ol> <p>Nota: se aparecer \u201cNon-pristine devices detected\u201d, use as a\u00e7\u00f5es <code>zap-disk</code> e <code>add-disk</code>.</p> <ol> <li> <p>Nova Compute nova-compute.yaml:</p> <pre><code>nova-compute:\n  config-flags: default_ephemeral_format=ext4\n  enable-live-migration: true\n  enable-resize: true\n  migration-auth-type: ssh\n  virt-type: qemu\n</code></pre> <pre><code>juju deploy -n 3 --to 0,1,2 --channel yoga/stable --config nova-compute.yaml nova-compute\n</code></pre> </li> <li> <p>MySQL InnoDB Cluster</p> <pre><code>juju deploy -n 3 --to lxd:0,lxd:1,lxd:2 --channel 8.0/stable mysql-innodb-cluster\n</code></pre> </li> <li> <p>Vault</p> <pre><code>juju deploy --to lxd:2 vault --channel 1.8/stable\njuju deploy --channel 8.0/stable mysql-router vault-mysql-router\njuju integrate vault-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate vault-mysql-router:shared-db vault:shared-db\n</code></pre> </li> <li> <p>Inicialize e unseal (veja a documenta\u00e7\u00e3o do charm).</p> </li> <li> <p>Gere a CA autoassinada:</p> <pre><code>juju run vault/leader generate-root-ca\n</code></pre> </li> <li> <p>Integre certificados:</p> <pre><code>juju integrate mysql-innodb-cluster:certificates vault:certificates\n</code></pre> </li> <li> <p>Neutron Networking neutron.yaml:</p> <pre><code>ovn-chassis:\n  bridge-interface-mappings: br-ex:eth0\n  ovn-bridge-mappings: physnet1:br-ex\nneutron-api:\n  neutron-security-groups: true\n  flat-network-providers: physnet1\n</code></pre> <pre><code>juju deploy -n 3 --to lxd:0,lxd:1,lxd:2 --channel 22.03/stable ovn-central\njuju deploy --to lxd:1 --channel yoga/stable --config neutron.yaml neutron-api\njuju deploy --channel yoga/stable neutron-api-plugin-ovn\njuju deploy --channel 22.03/stable --config neutron.yaml ovn-chassis\n\njuju integrate neutron-api-plugin-ovn:neutron-plugin neutron-api:neutron-plugin-api-subordinate\njuju integrate neutron-api-plugin-ovn:ovsdb-cms ovn-central:ovsdb-cms\njuju integrate ovn-chassis:ovsdb ovn-central:ovsdb\njuju integrate ovn-chassis:nova-compute nova-compute:neutron-plugin\njuju integrate neutron-api:certificates vault:certificates\njuju integrate neutron-api-plugin-ovn:certificates vault:certificates\njuju integrate ovn-central:certificates vault:certificates\njuju integrate ovn-chassis:certificates vault:certificates\n</code></pre> </li> <li> <p>Keystone</p> <pre><code>juju deploy --to lxd:0 --channel yoga/stable keystone\njuju deploy --channel 8.0/stable mysql-router keystone-mysql-router\njuju integrate keystone-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate keystone-mysql-router:shared-db keystone:shared-db\njuju integrate keystone:identity-service neutron-api:identity-service\njuju integrate keystone:certificates vault:certificates\n</code></pre> </li> <li> <p>RabbitMQ</p> <pre><code>juju deploy --to lxd:2 --channel 3.9/stable rabbitmq-server\njuju integrate rabbitmq-server:amqp neutron-api:amqp\njuju integrate rabbitmq-server:amqp nova-compute:amqp\n</code></pre> </li> <li> <p>Nova Cloud Controller ncc.yaml:</p> <pre><code>nova-cloud-controller:\n  network-manager: Neutron\n</code></pre> <pre><code>juju deploy --to lxd:2 --channel yoga/stable --config ncc.yaml nova-cloud-controller\njuju deploy --channel 8.0/stable mysql-router ncc-mysql-router\njuju integrate ncc-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate ncc-mysql-router:shared-db nova-cloud-controller:shared-db\n\njuju integrate nova-cloud-controller:identity-service keystone:identity-service\njuju integrate nova-cloud-controller:amqp rabbitmq-server:amqp\njuju integrate nova-cloud-controller:neutron-api neutron-api:neutron-api\njuju integrate nova-cloud-controller:cloud-compute nova-compute:cloud-compute\njuju integrate nova-cloud-controller:certificates vault:certificates\n</code></pre> </li> <li> <p>Placement</p> <pre><code>juju deploy --to lxd:2 --channel yoga/stable placement\njuju deploy --channel 8.0/stable mysql-router placement-mysql-router\njuju integrate placement-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate placement-mysql-router:shared-db placement:shared-db\njuju integrate placement:identity-service keystone:identity-service\njuju integrate placement:placement nova-cloud-controller:placement\njuju integrate placement:certificates vault:certificates\n</code></pre> </li> <li> <p>Horizon \u2013 OpenStack Dashboard</p> <pre><code>juju deploy --to lxd:2 --channel yoga/stable openstack-dashboard\njuju deploy --channel 8.0/stable mysql-router dashboard-mysql-router\njuju integrate dashboard-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate dashboard-mysql-router:shared-db openstack-dashboard:shared-db\njuju integrate openstack-dashboard:identity-service keystone:identity-service\njuju integrate openstack-dashboard:certificates vault:certificates\n</code></pre> </li> <li> <p>Glance</p> <pre><code>juju deploy --to lxd:2 --channel yoga/stable glance\njuju deploy --channel 8.0/stable mysql-router glance-mysql-router\njuju integrate glance-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate glance-mysql-router:shared-db glance:shared-db\njuju integrate glance:image-service nova-cloud-controller:image-service\njuju integrate glance:image-service nova-compute:image-service\njuju integrate glance:identity-service keystone:identity-service\njuju integrate glance:certificates vault:certificates\n</code></pre> </li> <li> <p>Ceph Monitor ceph-mon.yaml:</p> <pre><code>ceph-mon:\n  expected-osd-count: 3\n  monitor-count: 3\n</code></pre> <pre><code>juju deploy -n 3 --to lxd:0,lxd:1,lxd:2 --channel quincy/stable --config ceph-mon.yaml ceph-mon\njuju integrate ceph-mon:osd ceph-osd:mon\njuju integrate ceph-mon:client nova-compute:ceph\njuju integrate ceph-mon:client glance:ceph\n</code></pre> </li> <li> <p>Cinder cinder.yaml:</p> <pre><code>cinder:\n  block-device: None\n  glance-api-version: 2\n</code></pre> <pre><code>juju deploy --to lxd:1 --channel yoga/stable --config cinder.yaml cinder\njuju deploy --channel 8.0/stable mysql-router cinder-mysql-router\njuju integrate cinder-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate cinder-mysql-router:shared-db cinder:shared-db\njuju integrate cinder:cinder-volume-service nova-cloud-controller:cinder-volume-service\njuju integrate cinder:identity-service keystone:identity-service\njuju integrate cinder:amqp rabbitmq-server:amqp\njuju integrate cinder:image-service glance:image-service\njuju integrate cinder:certificates vault:certificates\n\njuju deploy --channel yoga/stable cinder-ceph\njuju integrate cinder-ceph:storage-backend cinder:storage-backend\njuju integrate cinder-ceph:ceph ceph-mon:client\njuju integrate cinder-ceph:ceph-access nova-compute:ceph-access\n</code></pre> </li> <li> <p>Ceph RADOS Gateway</p> <pre><code>juju deploy --to lxd:0 --channel quincy/stable ceph-radosgw\njuju integrate ceph-radosgw:mon ceph-mon:radosgw\n</code></pre> </li> <li> <p>Ceph\u2011OSD Integration</p> <pre><code>juju config ceph-osd osd-devices='/dev/sdb'\n</code></pre> </li> </ol>"},{"location":"roteiro3/main/#resultados-finais-e-proximos-passos","title":"Resultados finais e pr\u00f3ximos passos","text":"<p>Depois que todos os aplicativos foram implantados e as rela\u00e7\u00f5es adicionadas, aguarde at\u00e9 o <code>juju status</code> estabilizar, sem mensagens de erro. Exemplo de sa\u00edda: https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/install-openstack-juju-status.html#install-openstack-juju-status</p> <p>Voc\u00ea implantou o OpenStack com sucesso usando Juju e MAAS. O pr\u00f3ximo passo \u00e9 tornar a nuvem funcional para os usu\u00e1rios, configurando redes, imagens e ambientes de usu\u00e1rio.</p> <p>Info</p> <ul> <li>Dica: Git do Vault \u2013 Post\u2011Deployment Tasks</li> <li>Instalar CLI do Vault:</li> </ul> <pre><code>sudo snap install vault\nexport VAULT_ADDR=\"http://&lt;IP do Vault&gt;:8200\"\nvault operator init --key-shares=5 --key-threshold=3\n</code></pre> <p>Copie as 5 Unseal Keys e o Initial Root Token.</p> <pre><code>vault operator unseal &lt;Unseal Key&gt;  # repita 3x com chaves diferentes\n</code></pre> <p>Autorize o charm (dentro de 50\u202fminutos):</p> <pre><code>export VAULT_TOKEN=&lt;Initial Root Token&gt;\nvault token create --ttl=50m\njuju run vault/leader authorize-charm token=&lt;token&gt;\n</code></pre>"},{"location":"roteiro3/main/#setup","title":"Setup","text":""},{"location":"roteiro3/main/#configurando-o-openstack","title":"Configurando o OpenStack","text":"<p>Documenta\u00e7\u00e3o: Configurar OpenStack</p> <p>Agora vamos configurar:</p> <ul> <li>VMs (Nova)</li> <li>Volumes de disco (Cinder)</li> <li> <p>Rede virtual (Neutron)</p> </li> <li> <p>Carregar vari\u00e1veis de ambiente e autenticar (Keystone) via <code>openrc</code>.</p> </li> <li>Usar o Horizon para visualizar mudan\u00e7as.</li> <li>Importar imagem do Ubuntu Jammy para o Glance.</li> <li>Criar flavors.</li> <li>Criar rede externa.</li> <li>Criar rede interna e roteador.</li> </ul> <p>Aten\u00e7\u00e3o: execute TODOS OS COMANDOS no terminal <code>main</code> ou no Horizon. N\u00e3o nos NUCs!</p>"},{"location":"roteiro3/main/#passo-1-autenticacao","title":"Passo 1: Autentica\u00e7\u00e3o","text":"<p>Fa\u00e7a o download ou crie o arquivo <code>openrc</code> com suas credenciais do OpenStack (vari\u00e1veis como <code>OS_AUTH_URL</code>, <code>OS_USERNAME</code> etc).</p>"},{"location":"roteiro3/main/#passo-2-horizon","title":"Passo 2: Horizon","text":"<p>Acesse o Horizon como admin e mantenha aberto durante todo o setup.</p> <p>Dica: Domain name = <code>admin_domain</code></p>"},{"location":"roteiro3/main/#passo-3-imagens-e-flavors","title":"Passo 3: Imagens e Flavors","text":"<p>Instale o cliente OpenStack no <code>main</code>:</p> <pre><code>sudo snap install openstack-client --classic\nsource openrc\n</code></pre> <p>Verifique servi\u00e7os:</p> <pre><code>openstack service list\n</code></pre> <p>Ajuste rede:</p> <pre><code>juju config neutron-api enable-ml2-dns=\"true\"\njuju config neutron-api-plugin-ovn dns-servers=\"172.16.0.1\"\n</code></pre> <p>Importe a imagem do Ubuntu Jammy (consulte a URL na doc oficial):</p> <pre><code>openstack image create \"Ubuntu Jammy\" \\\n  --file ubuntu-22.04-server-cloudimg-amd64.img \\\n  --disk-format qcow2 \\\n  --container-format bare \\\n  --public\n</code></pre> <p>Crie os flavors:</p> Flavor Name vCPUs RAM (GB) Disk (GB) m1.tiny 1 1 20 m1.small 1 2 20 m1.medium 2 4 20 m1.large 4 8 20"},{"location":"roteiro3/main/#passo-4-rede-externa","title":"Passo 4: Rede Externa","text":"<p>Crie uma rede externa com faixa de aloca\u00e7\u00e3o entre <code>172.16.7.0/24</code> e <code>172.16.8.255</code>.</p>"},{"location":"roteiro3/main/#passo-5-rede-interna-e-roteador","title":"Passo 5: Rede Interna e Roteador","text":"<p>Use a subnet <code>192.169.0.0/24</code> (sem DNS) e configure o roteador.</p>"},{"location":"roteiro3/main/#passo-6-instancia","title":"Passo 6: Inst\u00e2ncia","text":"<ol> <li>Crie um key-pair:</li> </ol> <p><pre><code>openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey\n</code></pre> 2. Lance inst\u00e2ncia <code>m1.tiny</code> chamada <code>client</code>:</p> <p><pre><code>openstack server create \\\n  --flavor m1.tiny \\\n  --image \"Ubuntu Jammy\" \\\n  --key-name mykey \\\n  --network private-net client\n</code></pre> 3. Aloque floating IP:</p> <p><pre><code>openstack floating ip create external-net\nopenstack server add floating ip client &lt;FLOATING_IP&gt;\n</code></pre> 4. Teste SSH.</p>"},{"location":"roteiro3/main/#escalando-os-nos","title":"Escalando os n\u00f3s","text":"<ol> <li>Libere a m\u00e1quina ALLOCATED no MAAS.</li> <li>Adicione hypervisor:</li> </ol> <p><pre><code>juju add-unit nova-compute\n</code></pre> 3. Adicione block storage:</p> <pre><code>juju add-unit --to &lt;machine-id&gt; ceph-osd\n</code></pre>"},{"location":"roteiro3/main/#tarefas","title":"Tarefas","text":""},{"location":"roteiro3/main/#tarefa-1","title":"Tarefa 1","text":""},{"location":"roteiro3/main/#1-print-do-status-do-juju","title":"1. Print do Status do JUJU","text":""},{"location":"roteiro3/main/#2-print-do-dashboard-do-maas-com-as-maquinas","title":"2. Print do Dashboard do MAAS com as m\u00e1quinas","text":""},{"location":"roteiro3/main/#3-print-da-aba-compute-overview-no-openstack-dashboard","title":"3. Print da aba Compute Overview no OpenStack Dashboard","text":""},{"location":"roteiro3/main/#4-print-da-aba-compute-instances-no-openstack-dashboard","title":"4. Print da aba Compute Instances no OpenStack Dashboard","text":""},{"location":"roteiro3/main/#5-print-da-aba-network-topology-no-openstack-dashboard","title":"5. Print da aba Network Topology no OpenStack Dashboard","text":""},{"location":"roteiro3/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"roteiro3/main/#1-print-do-dashboard-do-maas-com-as-maquinas","title":"1. Print do Dashboard do MAAS com as m\u00e1quinas","text":""},{"location":"roteiro3/main/#2-print-da-aba-compute-overview-no-openstack-dashboard","title":"2. Print da aba Compute Overview no OpenStack Dashboard","text":""},{"location":"roteiro3/main/#3-print-da-aba-compute-instances-no-openstack-dashboard","title":"3. Print da aba Compute Instances no OpenStack Dashboard","text":""},{"location":"roteiro3/main/#4-print-da-aba-network-topology-no-openstack-dashboard","title":"4. Print da aba Network Topology no OpenStack Dashboard","text":"<ol> <li>Enumere as diferen\u00e7as entre os prints da Tarefa 1 e da Tarefa 2 e explique como cada recurso foi criado</li> </ol> <p>A diferen\u00e7a se deve devido a cria\u00e7\u00e3o de uma nova inst\u00e2ncia a partir de uma nova imagem (um flavor de tamanho tiny) e \u00e0 defini\u00e7\u00e3o de uma rede externa e interna, com a inst\u00e2ncia criada ligada \u00e0 rede interna.</p>"},{"location":"roteiro3/main/#tarefa-3","title":"Tarefa 3","text":"<p>A arquitetura de rede \u00e9 algo como:</p> <pre><code>flowchart LR\n    Internet((Internet))\n    Router1([Router 1])\n    Router2([Router 2])\n    Router3([Router 3])\n\n    Internet --&gt;|10.0.0.0/8| Router1\n    Router1 --&gt;|172.16.0.0/20| Router2\n    Router2 --&gt;|192.168.0.0/24| Router3\n    Router3 --&gt; Client</code></pre> <p></p>"},{"location":"roteiro3/main/#app","title":"App","text":""},{"location":"roteiro3/main/#uso-da-infraestrutura","title":"Uso da Infraestrutura","text":"<p>Levante as aplica\u00e7\u00f5es em VMs do OpenStack:</p> <ul> <li>2 inst\u00e2ncias com a API do projeto  </li> <li>1 inst\u00e2ncia com banco de dados  </li> <li>1 inst\u00e2ncia com Load Balancer (Nginx)</li> </ul> <p>Topologia de rede:</p> <pre><code>Interna: 192.169.0.0/24\n\u2514\u2500 Load Balancer (Nginx)\n\u251c\u2500 API (2 inst\u00e2ncias)\n\u2514\u2500 Banco de Dados\nExterna: 172.16.0.0/20\n</code></pre> <p>Aten\u00e7\u00e3o: escolha o menor flavor que atenda ao desempenho; em clouds comerciais, o custo \u00e9 proporcional ao tamanho do flavor e ao tempo de uso.</p>"},{"location":"roteiro3/main/#passos-de-implantacao","title":"Passos de implanta\u00e7\u00e3o","text":"<ol> <li> <p>Cria\u00e7\u00e3o das inst\u00e2ncias <pre><code># API (primeiro modelo)\nopenstack server create \\\n  --image jammy-amd64 \\\n  --flavor m1.tiny \\\n  --key-name chave \\\n  --network user1_net \\\n  --security-group Allow_SSH \\\n  api-1\n\n# API (segundo modelo)\nopenstack server create \\\n  --image jammy-amd64 \\\n  --flavor m1.tiny \\\n  --key-name chave \\\n  --network user1_net \\\n  --security-group Allow_SSH \\\n  api-2\n\n# Banco de Dados\nopenstack server create \\\n  --image jammy-amd64 \\\n  --flavor m1.tiny \\\n  --key-name chave \\\n  --network user1_net \\\n  --security-group Allow_SSH \\\n  database\n</code></pre></p> </li> <li> <p>Reserva e associa\u00e7\u00e3o de Floating IP</p> <pre><code>FLOATING_IP=$(openstack floating ip create \\\n  -f value -c floating_ip_address ext_net)\n\nopenstack server add floating ip api-1   $FLOATING_IP\nopenstack server add floating ip api-2   $FLOATING_IP\nopenstack server add floating ip database $FLOATING_IP\n\nopenstack server list\n</code></pre> </li> <li> <p>Configura\u00e7\u00e3o do Load Balancer (Nginx)</p> <pre><code>sudo apt update &amp;&amp; sudo apt install nginx -y\nsudo nano /etc/nginx/sites-available/default\nsudo systemctl restart nginx\nsudo systemctl status nginx\n</code></pre> </li> <li> <p>Deploy da API via Docker</p> <pre><code>sudo docker pull samueljabes/simple_authentication_api:v1.0.1\n\nsudo docker run -d -p 5000:5000 \\\n  -e POSTGRES_USER=postgres \\\n  -e POSTGRES_PASSWORD=sjcc9494 \\\n  -e POSTGRES_DB=cloud-auth \\\n  -e POSTGRES_HOST=172.16.8.99 \\\n  -e POSTGRES_PORT=5432 \\\n  samueljabes/simple_authentication_api:v1.0.1\n\nsudo docker ps\nsudo docker logs $(sudo docker ps -q --filter ancestor=samueljabes/simple_authentication_api:v1.0.1)\n</code></pre> </li> <li> <p>Prepara\u00e7\u00e3o do banco de dados</p> <pre><code># 1. Cria usu\u00e1rio e base\nsudo -u postgres psql &lt;&lt;EOF\nCREATE USER postgres WITH PASSWORD 'sjcc9494';\nCREATE DATABASE \"cloud-auth\" OWNER postgres;\nEOF\n\n# 2. Ajusta pg_hba.conf e reinicia\nsudo nano /etc/postgresql/14/main/pg_hba.conf\nsudo systemctl restart postgresql\n\n# 3. Importa script de cria\u00e7\u00e3o de tabelas\npsql -U postgres -d cloud-auth -f /tmp/users.sql\n\n# 4. Valida (lista tabelas)\n\\dt\n</code></pre> </li> </ol> <p>Assim, ao realizar o t\u00fanel para a inst\u00e2ncia onde o Load Balancer est\u00e1 instalado, n\u00f3s conseguimos acessar a API com esse fluxo de infra criado com o OpenStack:</p> <pre><code>ssh cloud@10.103.1.22 -L 8001:172.16.7.141:80\n</code></pre> <p>Ao abrir <code>localhost:8001</code>, obtemos:</p> <p></p> <p>Ent\u00e3o a arquitetura final \u00e9 algo como:</p> <pre><code>flowchart LR\n    subgraph private [192.169.0.0/24]\n        direction TB\n        lb e2@==&gt; api1[API]\n        lb e3@==&gt; api2[API]\n        api1 e4@==&gt; db\n        api2 e5@==&gt; db\n    end\n    user e1@==&gt;|request&lt;br&gt;172.16.0.0/20| lb\n    e1@{ animate: true }\n    e2@{ animate: true }\n    e3@{ animate: true }\n    e4@{ animate: true }\n    e5@{ animate: true }\n    lb@{ shape: div-rect, label: \"Load Balancer\" }\n    db@{ shape: cyl, label: \"Database\" }\n    user@{ img: \"https://insper.github.io/computacao-nuvem/assets/images/fontawesome-user-icon.png\", constraint: \"on\", h: 60, label: \"User\" }</code></pre>"},{"location":"roteiro4/main/","title":"Roteiro 4 \u2013 Identity e IaC","text":""},{"location":"roteiro4/main/#infra","title":"Infra","text":""},{"location":"roteiro4/main/#criando-a-hierarquia-de-projetos-separado-por-aluno","title":"Criando a hierarquia de projetos separado por aluno","text":"<p>Agora vamos ver como funciona a separa\u00e7\u00e3o l\u00f3gica de recursos para cada usu\u00e1rio. Em vez de criar redes, sub-redes, VMs e roteadores manualmente no Horizon ou CLI, vamos organizar tudo dentro de um dom\u00ednio com projetos e usu\u00e1rios distintos.</p>"},{"location":"roteiro4/main/#1-criar-um-domain","title":"1. Criar um Domain","text":"<ol> <li>Acesse Identity &gt; Domains.  </li> <li>Clique em Create Domain.  </li> <li>Preencha:  </li> <li>Name: <code>AlunosDomain</code> </li> <li>Description: (opcional)  </li> <li>Clique em Create Domain.</li> </ol>"},{"location":"roteiro4/main/#2-selecionar-o-novo-domain","title":"2. Selecionar o novo Domain","text":"<p>No canto superior direito do Horizon, escolha AlunosDomain como contexto de uso.</p>"},{"location":"roteiro4/main/#3-criar-projetos","title":"3. Criar Projetos","text":"<ol> <li>Acesse Identity &gt; Projects.  </li> <li>Clique em Create Project e preencha:  </li> <li>Name: siga o padr\u00e3o <code>kitX_nomeAluno</code> (ex.: <code>kitA_samuel</code>)  </li> <li>Description: (opcional)  </li> <li>Quotas: defina limites de CPU, RAM e disco se necess\u00e1rio.  </li> <li>Clique em Create Project.  </li> <li>Repita para cada aluno (por exemplo, <code>kitB_maria</code>).</li> </ol>"},{"location":"roteiro4/main/#4-criar-usuarios","title":"4. Criar Usu\u00e1rios","text":"<ol> <li>Acesse Identity &gt; Users.  </li> <li>Clique em Create User e preencha:  </li> <li>Username: <code>alunoX</code> </li> <li>Email: (opcional)  </li> <li>Password: (escolha uma senha segura)  </li> <li>Domain: <code>AlunosDomain</code> </li> <li>Default Project: o projeto respectivo (<code>kitX_nomeAluno</code>)  </li> <li>Marque o papel Admin (ou outro papel necess\u00e1rio).  </li> <li>Clique em Create User.  </li> <li>Repita para cada usu\u00e1rio.</li> </ol>"},{"location":"roteiro4/main/#5-atribuir-papeis-se-nao-feito-acima","title":"5. Atribuir Pap\u00e9is (se n\u00e3o feito acima)","text":"<ol> <li>Acesse Identity &gt; Projects e abra o projeto <code>kitX_nomeAluno</code>.  </li> <li>V\u00e1 at\u00e9 a aba Members &gt; Manage Members.  </li> <li>Adicione o usu\u00e1rio <code>alunoX</code> e atribua-lhe o papel Admin.  </li> <li>Clique em Save.</li> </ol>"},{"location":"roteiro4/main/#app","title":"App","text":""},{"location":"roteiro4/main/#criando-a-infraestrutura-utilizando-iac","title":"Criando a Infraestrutura utilizando IaC","text":"<p>Usaremos Terraform para automatizar a cria\u00e7\u00e3o da rede, sub-rede, router e inst\u00e2ncias dentro de cada projeto. Cada aluno deve trabalhar em sua pr\u00f3pria pasta, dentro do diret\u00f3rio MAIN do servidor. Abaixo, vamos exemplificar para o aluno Samuel e a organiza\u00e7\u00e3o \u00e9 a mesma para o outro aluno.</p>"},{"location":"roteiro4/main/#1-estrutura-de-pastas","title":"1. Estrutura de pastas","text":"<p>Dentro de <code>~/kitMSamuel/</code>:</p> <pre><code>kitMSamuel/\n\u2514\u2500 terraform/\n\u251c provider.tf\n\u251c network.tf\n\u251c router.tf\n\u251c instance1.tf\n\u2514 instance2.tf\n</code></pre>"},{"location":"roteiro4/main/#2-providertf","title":"2. provider.tf","text":"<pre><code># Define required providers\nterraform {\n  required_version = \"&gt;= 0.14.0\"\n  required_providers {\n    openstack = {\n      source  = \"terraform-provider-openstack/openstack\"\n      version = \"~&gt; 1.35.0\"\n    }\n  }\n}\n\n# Configure the OpenStack Provider\nprovider \"openstack\" {\n  user_name = \"Samuel\"\n  password  = \"sjcc9494\"\n  auth_url  = \"https://172.16.15.29:5000/v3\"\n  region    = \"RegionOne\"\n  insecure  = true\n}\n</code></pre>"},{"location":"roteiro4/main/#3-networktf","title":"3. network.tf","text":"<pre><code>resource \"openstack_networking_network_v2\" \"network_sam_1\" {\n  name           = \"network_sam_1\"\n  admin_state_up = \"true\"\n}\n\nresource \"openstack_networking_subnet_v2\" \"subnet_2\" {\n  network_id = openstack_networking_network_v2.network_sam_1.id\n  cidr       = \"192.167.199.0/24\"\n}\n</code></pre> <p>\u26a0\ufe0f Observa\u00e7\u00e3o: \u00e9 ideal que seja um nome \u00fanico por aluno em todos os arquivos.</p>"},{"location":"roteiro4/main/#4-routertf","title":"4. router.tf","text":"<pre><code>resource \"openstack_networking_router_v2\" \"router_2\" {\n  name                = \"user1_router\"\n  admin_state_up      = true\n  external_network_id = \"8931ac52-d339-4ba6-abb2-ad48aa5a4858\"\n}\n\nresource \"openstack_networking_router_interface_v2\" \"int_2\" {\n  router_id = openstack_networking_router_v2.router_2.id\n  subnet_id = openstack_networking_subnet_v2.subnet_2.id\n}\n</code></pre>"},{"location":"roteiro4/main/#5-instance1tf","title":"5. instance1.tf","text":"<pre><code>resource \"openstack_compute_instance_v2\" \"my_instance_1_sam\" {\n  name      = \"my_instance_1_sam\"\n  image_id  = \"1caed021-f9d6-43c8-b455-187b620a19a6\"\n  flavor_id = \"f5e13998-4362-416d-b29c-d3604cb51f4f\"\n  key_pair  = \"chave_sam\"\n\n  network {\n    name = \"network_sam_1\"\n  }\n}\n</code></pre>"},{"location":"roteiro4/main/#6-instance2tf","title":"6. instance2.tf","text":"<pre><code>resource \"openstack_compute_instance_v2\" \"my_instance_2_sam\" {\n  name      = \"my_instance_2_sam\"\n  image_id  = \"1caed021-f9d6-43c8-b455-187b620a19a6\"\n  flavor_id = \"f5e13998-4362-416d-b29c-d3604cb51f4f\"\n  key_pair  = \"chave_sam\"\n\n  network {\n    name = \"network_sam_1\"\n  }\n}\n</code></pre>"},{"location":"roteiro4/main/#7-credenciais-do-usuario","title":"7. Credenciais do usu\u00e1rio","text":"<ol> <li>No Horizon, acesse Project &gt; API Access e fa\u00e7a download do OpenStack RC File.</li> <li>Copie o conte\u00fado do arquivo para <code>~/kitX_nomeAluno/seu_openrc.sh</code>.</li> <li>Torne-o execut\u00e1vel:</li> </ol> <p><pre><code>chmod +x ~/kitX_nomeAluno/seu_openrc.sh\n</code></pre> 4. Carregue as vari\u00e1veis de ambiente:</p> <pre><code>source ~/kitX_nomeAluno/seu_openrc.sh\n</code></pre> <p>Se ocorrer erro SSL, voc\u00ea pode:</p> <ul> <li><code>export OS_CACERT=/caminho/para/certificado.pem</code></li> <li>ou usar <code>export OS_VERIFY=False</code> (n\u00e3o recomendado em produ\u00e7\u00e3o).</li> </ul>"},{"location":"roteiro4/main/#8-executando-o-terraform","title":"8. Executando o Terraform","text":"<pre><code>cd ~/kitX_nomeAluno/terraform\nterraform init\nterraform plan    # revisa o que ser\u00e1 criado\nterraform apply   # confirma e executa a cria\u00e7\u00e3o\n</code></pre>"},{"location":"roteiro4/main/#9-verificacao","title":"9. Verifica\u00e7\u00e3o","text":"<pre><code>openstack network list\nopenstack subnet list\nopenstack router list\nopenstack server list\n</code></pre>"},{"location":"roteiro4/main/#exercise-checkpoint","title":"Exercise CheckPoint","text":"<p>Para cada aluno, temos:</p> <ol> <li>Identity &gt; Projects </li> <li>Identity &gt; Users </li> <li> <p>Compute &gt; Overview</p> <ul> <li> <p>Samuel </p> </li> <li> <p>Lucas </p> </li> </ul> </li> <li> <p>Compute &gt; Instances</p> <ul> <li> <p>Samuel </p> </li> <li> <p>Lucas </p> </li> </ul> </li> <li> <p>Network Topology</p> <ul> <li> <p>Samuel </p> </li> <li> <p>Lucas </p> </li> </ul> </li> </ol>"},{"location":"roteiro4/main/#criando-um-plano-de-disaster-recovery-e-sla","title":"Criando um plano de Disaster Recovery e SLA","text":""},{"location":"roteiro4/main/#questoes","title":"QUEST\u00d5ES","text":"<ol> <li> <p>Voc\u00ea \u00e9 o CTO de uma empresa com v\u00e1rias capitais no Brasil e precisa implantar um sistema cr\u00edtico, de baixo custo e com dados sigilosos.</p> <ul> <li>Voc\u00ea escolheria Public Cloud ou Private Cloud? Por qu\u00ea?</li> </ul> <p>Private Cloud, pois garante controle f\u00edsico e l\u00f3gico dos dados sigilosos, atendimento a normas de privacidade (LGPD), custos previs\u00edveis (CapEx) e customiza\u00e7\u00e3o completa de seguran\u00e7a e rede.</p> </li> <li> <p>Explique ao RH por que sua equipe precisa de um time de DevOps.</p> <p>Um time de DevOps funciona como uma ponte entre quem cria o software (desenvolvedores) e quem mant\u00e9m tudo funcionando (opera\u00e7\u00f5es). Em vez de fazer tudo \u201cna m\u00e3o\u201d (configurar servidores, instalar atualiza\u00e7\u00f5es, copiar arquivos), eles usam scripts e ferramentas que automatizam essas tarefas repetitivas. Isso traz tr\u00eas grandes benef\u00edcios:</p> <ol> <li> <p>Menos erros e mais rapidez  Ao automatizar a configura\u00e7\u00e3o de servidores e o deploy de novas vers\u00f5es, evitamos que algu\u00e9m esque\u00e7a um passo ou digite algo errado. O resultado chega mais r\u00e1pido e sem surpresas.</p> </li> <li> <p>Ambientes sempre iguais  O que funciona no ambiente de testes vai funcionar em produ\u00e7\u00e3o, porque as mesmas instru\u00e7\u00f5es autom\u00e1ticas s\u00e3o usadas em todos os lugares. Assim, n\u00e3o temos aquele \u201cna minha m\u00e1quina funcionou, mas no cliente n\u00e3o\u201d.</p> </li> <li> <p>Monitoramento e resposta imediata  O time de DevOps tamb\u00e9m instala ferramentas que ficam de olho no sistema 24 horas por dia. Se algo sair do normal, eles recebem um alerta e podem corrigir antes que o usu\u00e1rio perceba, mantendo nossos servi\u00e7os est\u00e1veis.</p> </li> </ol> </li> <li> <p>Agora, planeje um ambiente resiliente para mitigar interrup\u00e7\u00f5es e indisponibilidades:</p> <p>Para mitigar falhas de hardware, interrup\u00e7\u00f5es de energia, ataques cibern\u00e9ticos ou erros humanos, adotamos uma arquitetura multi\u2011zona com balanceadores de carga que fazem failover autom\u00e1tico entre data centers. Runbooks documentados e exerc\u00edcios de recupera\u00e7\u00e3o (drills) garantem que a equipe saiba exatamente o que fazer em cada cen\u00e1rio. A pol\u00edtica de backup combina c\u00f3pias incrementais di\u00e1rias e snapshots completos semanais, todas criptografadas e armazenadas off\u2011site, com testes peri\u00f3dicos de restaura\u00e7\u00e3o. Por fim, implementamos alta disponibilidade por meio de clusters de banco de dados e mensageria, armazenamento Ceph com r\u00e9plica tripla e redes redundantes com health\u2011checks e alertas autom\u00e1ticos, assegurando continuidade dos servi\u00e7os mesmo diante de incidentes.</p> </li> </ol>"}]}